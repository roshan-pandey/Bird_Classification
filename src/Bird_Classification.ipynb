{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c361b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, Dropout, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044510b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = pd.read_csv('../data/birds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8606ff3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class index</th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>data set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train/ABBOTTS BABBLER/001.jpg</td>\n",
       "      <td>ABBOTTS BABBLER</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>train/ABBOTTS BABBLER/002.jpg</td>\n",
       "      <td>ABBOTTS BABBLER</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>train/ABBOTTS BABBLER/003.jpg</td>\n",
       "      <td>ABBOTTS BABBLER</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>train/ABBOTTS BABBLER/004.jpg</td>\n",
       "      <td>ABBOTTS BABBLER</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>train/ABBOTTS BABBLER/005.jpg</td>\n",
       "      <td>ABBOTTS BABBLER</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class index                      filepaths           labels data set\n",
       "0            0  train/ABBOTTS BABBLER/001.jpg  ABBOTTS BABBLER    train\n",
       "1            0  train/ABBOTTS BABBLER/002.jpg  ABBOTTS BABBLER    train\n",
       "2            0  train/ABBOTTS BABBLER/003.jpg  ABBOTTS BABBLER    train\n",
       "3            0  train/ABBOTTS BABBLER/004.jpg  ABBOTTS BABBLER    train\n",
       "4            0  train/ABBOTTS BABBLER/005.jpg  ABBOTTS BABBLER    train"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f0633c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = birds[birds['data set'] == 'train']\n",
    "test = birds[birds['data set'] == 'test']\n",
    "val = birds[birds['data set'] == 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31644eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54652, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb688b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2dfa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd2af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad8d56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54652 validated image filenames belonging to 375 classes.\n",
      "Found 1875 validated image filenames belonging to 375 classes.\n",
      "Found 1875 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1.0/255.0)\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    directory=\"../data/\",\n",
    "    x_col=\"filepaths\",\n",
    "    y_col=\"labels\",\n",
    "    subset=\"training\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(256, 256),\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=val,\n",
    "    directory=\"../data/\",\n",
    "    x_col=\"filepaths\",\n",
    "    y_col=\"labels\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(256, 256),\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test,\n",
    "    directory=\"../data/\",\n",
    "    x_col=\"filepaths\",\n",
    "    y_col=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(256, 256),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30239a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint callback is used to save only the best model out of all the epochs...\n",
    "checkpoint = ModelCheckpoint(filepath=\"../models/resnet.h5\", verbose=2, save_best_only=True)\n",
    "\n",
    "# EarlyStopping callback is used to stop the training when accuracy doesn't improve for 5 epochs...\n",
    "early_stop = EarlyStopping(monitor=\"accuracy\", min_delta=0, patience=5)\n",
    "\n",
    "callbacks = [early_stop, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e594ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(history, model):\n",
    "    fig, axes = plt.subplots(1, 2, figsize = (10, 5)) # fig of 1 row and 2 cols with 10x5 size...\n",
    "    # In First column of figure, plotting accuracy and val accuracy from trained model object(history)...\n",
    "    axes[0].plot(range(1, len(history.history['accuracy']) + 1), history.history['accuracy'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Accuracy') \n",
    "    axes[0].plot(range(1, len(history.history['val_accuracy']) + 1), history.history['val_accuracy'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Accuracy')\n",
    "    axes[0].set_xlabel('Epochs', fontsize = 14)\n",
    "    axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
    "    axes[0].set_title(f\"{model} Accuracy Training vs Testing\", fontsize = 14)\n",
    "    axes[0].legend(loc = 'best') # Location of the legend, whereever is more empty space put legent there (loc= 'best')...\n",
    "    # In Second column of figure, plotting accuracy and val accuracy from trained model object(history)...\n",
    "    axes[1].plot(range(1, len(history.history['loss']) + 1), history.history['loss'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Loss')\n",
    "    axes[1].plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Loss')\n",
    "    axes[1].set_xlabel('Epochs', fontsize = 14)\n",
    "    axes[1].set_ylabel('Loss',fontsize = 14)\n",
    "    axes[1].set_title(f\"{model} Loss Training vs Testing\", fontsize = 14)\n",
    "    axes[1].legend(loc = 'best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28a6232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(base_model):\n",
    "    \n",
    "    # Removes the values in the graph(network connections) but do not delete the graph itself... helps in RAM cleaning...\n",
    "    tf.keras.backend.clear_session() \n",
    "\n",
    "    # input of size 256x256x3... hight x width = 256 x 256, number of channels = 3...\n",
    "    input = Input(name = 'img_input', shape=(256, 256, 3))\n",
    "\n",
    "    # Making Base model layers as non-trainable...\n",
    "    for layer in base_model.layers:\n",
    "      layer.trainable = False\n",
    "\n",
    "    input_layer = base_model(input) # defining input layer...\n",
    "\n",
    "\n",
    "    # Functional API of keras is used for this network...\n",
    "\n",
    "    # Convolution layer with 32 filters of size 3x3 and stride = 1x1, activation function used is ReLU and \"valid\" padding to keep the input and output size same...\n",
    "    # he normal kernel initializer is used as it performs well with non-linear activation functions like ReLU... \n",
    "    conv = Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding = 'valid', activation = 'relu', \n",
    "              kernel_initializer = tf.keras.initializers.he_normal())(input_layer)\n",
    "    pool = GlobalAveragePooling2D()(conv) # the pool size is set to the input size and it outputs the average of the pool...\n",
    "    d1 = Dense(units = 64, activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal())(pool)\n",
    "    drop1 = Dropout(0.5)(d1) # dropout was used to deactivate some of the nodes to avoid overfitting...\n",
    "    d2 = Dense(units = 128, activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal())(drop1)\n",
    "    bn = BatchNormalization()(d2) # batch normalization was used normalize weights batch wise and in turn reduce the chances of overfitting...\n",
    "    drop2 = Dropout(0.2)(bn)\n",
    "    d3 = Dense(units = 64, activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal())(drop2)\n",
    "    Out = Dense(units = 375, activation = 'softmax', kernel_initializer = tf.keras.initializers.he_normal())(d3)\n",
    "    model = tf.keras.Model(input, Out) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f0386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 6.0351 - accuracy: 0.0030\n",
      "Epoch 00001: val_loss improved from inf to 5.92825, saving model to ../models\\resnet.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1707/1707 [==============================] - 287s 163ms/step - loss: 6.0351 - accuracy: 0.0030 - val_loss: 5.9283 - val_accuracy: 0.0027\n",
      "Epoch 2/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.9234 - accuracy: 0.0042\n",
      "Epoch 00002: val_loss did not improve from 5.92825\n",
      "1707/1707 [==============================] - 270s 158ms/step - loss: 5.9234 - accuracy: 0.0042 - val_loss: 5.9305 - val_accuracy: 0.0027\n",
      "Epoch 3/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.9198 - accuracy: 0.0043\n",
      "Epoch 00003: val_loss did not improve from 5.92825\n",
      "1707/1707 [==============================] - 270s 158ms/step - loss: 5.9198 - accuracy: 0.0043 - val_loss: 5.9328 - val_accuracy: 0.0027\n",
      "Epoch 4/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.9183 - accuracy: 0.0045\n",
      "Epoch 00004: val_loss did not improve from 5.92825\n",
      "1707/1707 [==============================] - 272s 159ms/step - loss: 5.9183 - accuracy: 0.0045 - val_loss: 5.9345 - val_accuracy: 0.0027\n",
      "Epoch 5/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.9179 - accuracy: 0.0045\n",
      "Epoch 00005: val_loss did not improve from 5.92825\n",
      "1707/1707 [==============================] - 272s 159ms/step - loss: 5.9179 - accuracy: 0.0045 - val_loss: 5.9357 - val_accuracy: 0.0027\n",
      "Epoch 6/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.9177 - accuracy: 0.0045\n",
      "Epoch 00006: val_loss did not improve from 5.92825\n",
      "1707/1707 [==============================] - 272s 159ms/step - loss: 5.9177 - accuracy: 0.0045 - val_loss: 5.9364 - val_accuracy: 0.0027\n",
      "Epoch 7/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.9176 - accuracy: 0.0046\n",
      "Epoch 00007: val_loss did not improve from 5.92825\n",
      "1707/1707 [==============================] - 271s 158ms/step - loss: 5.9176 - accuracy: 0.0046 - val_loss: 5.9369 - val_accuracy: 0.0027\n",
      "Epoch 8/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.9177 - accuracy: 0.0046\n",
      "Epoch 00008: val_loss did not improve from 5.92825\n",
      "1707/1707 [==============================] - 271s 159ms/step - loss: 5.9177 - accuracy: 0.0046 - val_loss: 5.9371 - val_accuracy: 0.0027\n",
      "Epoch 9/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.9174 - accuracy: 0.0046\n",
      "Epoch 00009: val_loss did not improve from 5.92825\n",
      "1707/1707 [==============================] - 271s 159ms/step - loss: 5.9174 - accuracy: 0.0046 - val_loss: 5.9373 - val_accuracy: 0.0027\n",
      "Epoch 10/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.9167 - accuracy: 0.0046\n",
      "Epoch 00010: val_loss did not improve from 5.92825\n",
      "1707/1707 [==============================] - 272s 159ms/step - loss: 5.9167 - accuracy: 0.0046 - val_loss: 5.9374 - val_accuracy: 0.0027\n",
      "Epoch 11/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.8973 - accuracy: 0.0059\n",
      "Epoch 00011: val_loss improved from 5.92825 to 5.92468, saving model to ../models\\resnet.h5\n",
      "1707/1707 [==============================] - 273s 160ms/step - loss: 5.8973 - accuracy: 0.0059 - val_loss: 5.9247 - val_accuracy: 0.0032\n",
      "Epoch 12/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.8501 - accuracy: 0.0069\n",
      "Epoch 00012: val_loss improved from 5.92468 to 5.88626, saving model to ../models\\resnet.h5\n",
      "1707/1707 [==============================] - 273s 160ms/step - loss: 5.8501 - accuracy: 0.0069 - val_loss: 5.8863 - val_accuracy: 0.0043\n",
      "Epoch 13/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.8170 - accuracy: 0.0075\n",
      "Epoch 00013: val_loss improved from 5.88626 to 5.86310, saving model to ../models\\resnet.h5\n",
      "1707/1707 [==============================] - 273s 160ms/step - loss: 5.8170 - accuracy: 0.0075 - val_loss: 5.8631 - val_accuracy: 0.0037\n",
      "Epoch 14/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.7932 - accuracy: 0.0080\n",
      "Epoch 00014: val_loss improved from 5.86310 to 5.84906, saving model to ../models\\resnet.h5\n",
      "1707/1707 [==============================] - 272s 159ms/step - loss: 5.7932 - accuracy: 0.0080 - val_loss: 5.8491 - val_accuracy: 0.0043\n",
      "Epoch 15/50\n",
      "1708/1707 [==============================] - ETA: 0s - loss: 5.7748 - accuracy: 0.0072\n",
      "Epoch 00015: val_loss improved from 5.84906 to 5.81573, saving model to ../models\\resnet.h5\n",
      "1707/1707 [==============================] - 280s 164ms/step - loss: 5.7748 - accuracy: 0.0072 - val_loss: 5.8157 - val_accuracy: 0.0048\n",
      "Epoch 16/50\n",
      " 172/1707 [==>...........................] - ETA: 4:08 - loss: 5.7620 - accuracy: 0.0091"
     ]
    }
   ],
   "source": [
    "# Loading weights of the ResNet101 pre-trained model without including top layers... imagenet is a dataset on which ResNet101 was trained...\n",
    "resnet_model = ResNet101(input_tensor = input, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "res_model = network(resnet_model)\n",
    "\n",
    "adam = Adam(learning_rate=0.001) # ADAM optimizer was used to reach the optimal weights...\n",
    "res_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fitting/training model...\n",
    "res_history = res_model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch = len(train) / BATCH_SIZE, # number of steps in each epoch...\n",
    "    callbacks=callbacks,\n",
    "    epochs = 50, \n",
    "    validation_data = valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7941dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(res_history, \"ResNet101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576acd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading weights of the vgg16 pre-trained model without including top layers... imagenet is a dataset on which vgg16 was trained...\n",
    "vgg16_model = VGG16(input_tensor = input, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "vgg_model = network(vgg16_model)\n",
    "\n",
    "adam = Adam(learning_rate=0.001) # ADAM optimizer was used to reach the optimal weights...\n",
    "vgg_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fitting/training model...\n",
    "vgg_history = vgg_model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch = len(train) / BATCH_SIZE, # number of steps in each epoch...\n",
    "    callbacks=callbacks,\n",
    "    epochs = 50, \n",
    "    validation_data = valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(vgg_history, \"VGG16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a83751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading weights of the InceptionV3 pre-trained model without including top layers... imagenet is a dataset on which InceptionV3 was trained...\n",
    "inception_model = InceptionV3(input_tensor = input, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "incepV3_model = network(inception_model)\n",
    "\n",
    "adam = Adam(learning_rate=0.001) # ADAM optimizer was used to reach the optimal weights...\n",
    "incepV3_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fitting/training model...\n",
    "incepV3_history = incepV3_model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch = len(train) / BATCH_SIZE, # number of steps in each epoch...\n",
    "    callbacks=callbacks,\n",
    "    epochs = 50, \n",
    "    validation_data = valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(incepV3_history, \"InceptionV3\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
