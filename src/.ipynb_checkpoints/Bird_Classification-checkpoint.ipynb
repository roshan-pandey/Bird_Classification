{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ce5e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, Dropout, Flatten, Activation, BatchNormalization, Dropout, GlobalAveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ab3708",
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = pd.read_csv('../data/birds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7687f791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class index</th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>data set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train/ABBOTTS BABBLER/001.jpg</td>\n",
       "      <td>ABBOTTS BABBLER</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>train/ABBOTTS BABBLER/002.jpg</td>\n",
       "      <td>ABBOTTS BABBLER</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>train/ABBOTTS BABBLER/003.jpg</td>\n",
       "      <td>ABBOTTS BABBLER</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>train/ABBOTTS BABBLER/004.jpg</td>\n",
       "      <td>ABBOTTS BABBLER</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>train/ABBOTTS BABBLER/005.jpg</td>\n",
       "      <td>ABBOTTS BABBLER</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class index                      filepaths           labels data set\n",
       "0            0  train/ABBOTTS BABBLER/001.jpg  ABBOTTS BABBLER    train\n",
       "1            0  train/ABBOTTS BABBLER/002.jpg  ABBOTTS BABBLER    train\n",
       "2            0  train/ABBOTTS BABBLER/003.jpg  ABBOTTS BABBLER    train\n",
       "3            0  train/ABBOTTS BABBLER/004.jpg  ABBOTTS BABBLER    train\n",
       "4            0  train/ABBOTTS BABBLER/005.jpg  ABBOTTS BABBLER    train"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bc7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = birds[birds['data set'] == 'train']\n",
    "test = birds[birds['data set'] == 'test']\n",
    "val = birds[birds['data set'] == 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b75983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54652, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd83bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf24a63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56054f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ba5424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54652 validated image filenames belonging to 375 classes.\n",
      "Found 1875 validated image filenames belonging to 375 classes.\n",
      "Found 1875 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1.0/255.0, \n",
    "                           shear_range=0.1, \n",
    "                           zoom_range=0.1, \n",
    "                           horizontal_flip=True, \n",
    "                           vertical_flip = True)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    directory=\"../data/\",\n",
    "    x_col=\"filepaths\",\n",
    "    y_col=\"labels\",\n",
    "    subset=\"training\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(256, 256),\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0 / 255.0,\n",
    "                                   shear_range=0.1, \n",
    "                                   zoom_range=0.1, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip = True)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=val,\n",
    "    directory=\"../data/\",\n",
    "    x_col=\"filepaths\",\n",
    "    y_col=\"labels\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(256, 256),\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test,\n",
    "    directory=\"../data/\",\n",
    "    x_col=\"filepaths\",\n",
    "    y_col=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(256, 256),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db9919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint callback is used to save only the best model out of all the epochs...\n",
    "checkpoint = ModelCheckpoint(filepath=\"../models/resnet.h5\", verbose=2, save_best_only=True)\n",
    "vgg_checkpoint = ModelCheckpoint(filepath=\"../models/vgg16.h5\", verbose=2, save_best_only=True)\n",
    "incepV3_checkpoint = ModelCheckpoint(filepath=\"../models/inception.h5\", verbose=2, save_best_only=True)\n",
    "xcep_checkpoint = ModelCheckpoint(filepath=\"../models/Xception.h5\", verbose=2, save_best_only=True)\n",
    "\n",
    "\n",
    "# EarlyStopping callback is used to stop the training when accuracy doesn't improve for 5 epochs...\n",
    "early_stop = EarlyStopping(monitor=\"accuracy\", min_delta=0, patience=5)\n",
    "\n",
    "callbacks = [early_stop, checkpoint]\n",
    "vgg_callbacks = [early_stop, vgg_checkpoint]\n",
    "incepV3_callbacks = [early_stop, incepV3_checkpoint]\n",
    "xcep_callbacks = [early_stop, xcep_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f7e8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(history, model):\n",
    "    fig, axes = plt.subplots(1, 2, figsize = (10, 5)) # fig of 1 row and 2 cols with 10x5 size...\n",
    "    # In First column of figure, plotting accuracy and val accuracy from trained model object(history)...\n",
    "    axes[0].plot(range(1, len(history.history['accuracy']) + 1), history.history['accuracy'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Accuracy') \n",
    "    axes[0].plot(range(1, len(history.history['val_accuracy']) + 1), history.history['val_accuracy'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Accuracy')\n",
    "    axes[0].set_xlabel('Epochs', fontsize = 14)\n",
    "    axes[0].set_ylabel('Accuracy',fontsize = 14)\n",
    "    axes[0].set_title(f\"{model} Accuracy Training vs Testing\", fontsize = 14)\n",
    "    axes[0].legend(loc = 'best') # Location of the legend, whereever is more empty space put legent there (loc= 'best')...\n",
    "    # In Second column of figure, plotting accuracy and val accuracy from trained model object(history)...\n",
    "    axes[1].plot(range(1, len(history.history['loss']) + 1), history.history['loss'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Loss')\n",
    "    axes[1].plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Loss')\n",
    "    axes[1].set_xlabel('Epochs', fontsize = 14)\n",
    "    axes[1].set_ylabel('Loss',fontsize = 14)\n",
    "    axes[1].set_title(f\"{model} Loss Training vs Testing\", fontsize = 14)\n",
    "    axes[1].legend(loc = 'best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67b50ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input of size 256x256x3... hight x width = 256 x 256, number of channels = 3...\n",
    "input = Input(name = 'img_input', shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e58e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(base_model, input):\n",
    "    \n",
    "    # Removes the values in the graph(network connections) but do not delete the graph itself... helps in RAM cleaning...\n",
    "    tf.keras.backend.clear_session() \n",
    "\n",
    "    # Making Base model layers as non-trainable...\n",
    "    for layer in base_model.layers:\n",
    "      layer.trainable = False\n",
    "\n",
    "    input_layer = base_model(input) # defining input layer...\n",
    "\n",
    "\n",
    "    # Functional API of keras is used for this network...\n",
    "\n",
    "    # Convolution layer with 32 filters of size 3x3 and stride = 1x1, activation function used is ReLU and \"valid\" padding to keep the input and output size same...\n",
    "    # he normal kernel initializer is used as it performs well with non-linear activation functions like ReLU... \n",
    "    conv = Conv2D(filters = 32, kernel_size = (7, 7), strides = (1, 1), padding = 'valid', activation = 'relu', \n",
    "              kernel_initializer = tf.keras.initializers.he_normal())(input_layer)\n",
    "    pool = GlobalAveragePooling2D()(conv) # the pool size is set to the input size and it outputs the average of the pool...\n",
    "    d1 = Dense(units = 64, activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal())(pool)\n",
    "    drop1 = Dropout(0.5)(d1) # dropout was used to deactivate some of the nodes to avoid overfitting...\n",
    "    d2 = Dense(units = 128, activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal())(drop1)\n",
    "    bn = BatchNormalization()(d2) # batch normalization was used normalize weights batch wise and in turn reduce the chances of overfitting...\n",
    "    drop2 = Dropout(0.2)(bn)\n",
    "    d3 = Dense(units = 64, activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal())(drop2)\n",
    "    Out = Dense(units = 375, activation = 'softmax', kernel_initializer = tf.keras.initializers.he_normal())(d3)\n",
    "    model = tf.keras.Model(input, Out) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ae0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(base_model, input):\n",
    "    \n",
    "    # Removes the values in the graph(network connections) but do not delete the graph itself... helps in RAM cleaning...\n",
    "    tf.keras.backend.clear_session() \n",
    "\n",
    "    # Making Base model layers as non-trainable...\n",
    "    for layer in base_model.layers:\n",
    "      layer.trainable = False\n",
    "\n",
    "    input_layer = base_model(input) # defining input layer...\n",
    "\n",
    "\n",
    "    # Functional API of keras is used for this network...\n",
    "\n",
    "    # Convolution layer with 32 filters of size 3x3 and stride = 1x1, activation function used is ReLU and \"valid\" padding to keep the input and output size same...\n",
    "    # he normal kernel initializer is used as it performs well with non-linear activation functions like ReLU... \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (7, 7), strides = (1, 1), padding = 'valid', activation = 'relu', \n",
    "              kernel_initializer = tf.keras.initializers.he_normal()))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(units = 64, activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal()))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 128, activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 64, activation = 'relu', kernel_initializer = tf.keras.initializers.he_normal()))\n",
    "    model.add(Dense(units = 375, activation = 'softmax', kernel_initializer = tf.keras.initializers.he_normal()))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4877bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 4\n",
    "# num_val_samples = len(train) // k\n",
    "# num_epochs = 100\n",
    "# all_scores = []\n",
    "\n",
    "# for i in range(k):\n",
    "#     print(f'Processing Fold #{i}')\n",
    "#     val_data = train[i * num_val_samples: (i+1) * num_val_samples]\n",
    "#     part_x_data = np.concatenate([train[: i*num_val_samples], train[(i+1)*num_val_samples:]], axis = 0)\n",
    "    \n",
    "#     part_x_data = pd.DataFrame(part_x_data)\n",
    "#     part_x_data.columns = ['class index', 'filepaths', 'labels', 'data set']\n",
    "#     print(part_x_data.head(5))\n",
    "#     # Loading weights of the ResNet101 pre-trained model without including top layers... imagenet is a dataset on which ResNet101 was trained...\n",
    "#     resnet_model = ResNet101(input_tensor = input, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "#     res_model = network(resnet_model, input)\n",
    "\n",
    "#     adam = Adam(learning_rate=0.001) # ADAM optimizer was used to reach the optimal weights...\n",
    "#     res_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "#     train_generator, valid_generator = data_generator(part_x_data, val_data)\n",
    "    \n",
    "#     # Fitting/training model...\n",
    "#     res_history = res_model.fit(\n",
    "#         train_generator, \n",
    "#         steps_per_epoch = len(train) / BATCH_SIZE, # number of steps in each epoch...\n",
    "#         callbacks=callbacks,\n",
    "#         epochs = num_epochs, \n",
    "#         validation_data = valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bca71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 6.0036 - accuracy: 0.0034\n",
      "Epoch 00001: val_loss improved from inf to 5.92939, saving model to ../models\\resnet.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3415/3415 [==============================] - 727s 210ms/step - loss: 6.0036 - accuracy: 0.0034 - val_loss: 5.9294 - val_accuracy: 0.0027\n",
      "Epoch 2/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 5.9212 - accuracy: 0.0043\n",
      "Epoch 00002: val_loss did not improve from 5.92939\n",
      "3415/3415 [==============================] - 557s 163ms/step - loss: 5.9212 - accuracy: 0.0043 - val_loss: 5.9327 - val_accuracy: 0.0027\n",
      "Epoch 3/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 5.9189 - accuracy: 0.0045\n",
      "Epoch 00003: val_loss did not improve from 5.92939\n",
      "3415/3415 [==============================] - 559s 164ms/step - loss: 5.9189 - accuracy: 0.0045 - val_loss: 5.9351 - val_accuracy: 0.0027\n",
      "Epoch 4/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 5.9183 - accuracy: 0.0045\n",
      "Epoch 00004: val_loss did not improve from 5.92939\n",
      "3415/3415 [==============================] - 559s 164ms/step - loss: 5.9183 - accuracy: 0.0045 - val_loss: 5.9364 - val_accuracy: 0.0027\n",
      "Epoch 5/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 5.9181 - accuracy: 0.0045\n",
      "Epoch 00005: val_loss did not improve from 5.92939\n",
      "3415/3415 [==============================] - 581s 170ms/step - loss: 5.9181 - accuracy: 0.0045 - val_loss: 5.9371 - val_accuracy: 0.0027\n",
      "Epoch 6/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 5.9181 - accuracy: 0.0044\n",
      "Epoch 00006: val_loss did not improve from 5.92939\n",
      "3415/3415 [==============================] - 559s 164ms/step - loss: 5.9181 - accuracy: 0.0044 - val_loss: 5.9374 - val_accuracy: 0.0027\n",
      "Epoch 7/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 5.9180 - accuracy: 0.0046\n",
      "Epoch 00007: val_loss did not improve from 5.92939\n",
      "3415/3415 [==============================] - 557s 163ms/step - loss: 5.9180 - accuracy: 0.0046 - val_loss: 5.9376 - val_accuracy: 0.0027\n",
      "Epoch 8/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 5.9180 - accuracy: 0.0044\n",
      "Epoch 00008: val_loss did not improve from 5.92939\n",
      "3415/3415 [==============================] - 604s 177ms/step - loss: 5.9180 - accuracy: 0.0044 - val_loss: 5.9376 - val_accuracy: 0.0027\n",
      "Epoch 9/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 5.9180 - accuracy: 0.0046\n",
      "Epoch 00009: val_loss did not improve from 5.92939\n",
      "3415/3415 [==============================] - 601s 176ms/step - loss: 5.9180 - accuracy: 0.0046 - val_loss: 5.9375 - val_accuracy: 0.0027\n",
      "Epoch 10/100\n",
      "2248/3415 [==================>...........] - ETA: 3:17 - loss: 5.9181 - accuracy: 0.0041"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3480/3759532699.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Fitting/training model...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m res_history = res_model.fit(\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# number of steps in each epoch...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\datascience\\python\\machine_learning\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loading weights of the ResNet101 pre-trained model without including top layers... imagenet is a dataset on which ResNet101 was trained...\n",
    "resnet_model = ResNet101(input_tensor = input, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "res_model = network(resnet_model, input)\n",
    "\n",
    "adam = Adam(learning_rate=0.001) # ADAM optimizer was used to reach the optimal weights...\n",
    "res_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fitting/training model...\n",
    "res_history = res_model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch = len(train) / BATCH_SIZE, # number of steps in each epoch...\n",
    "    callbacks=callbacks,\n",
    "    epochs = EPOCHS, \n",
    "    validation_data = valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a9c5efa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3480/3563200927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplotter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ResNet101\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'res_history' is not defined"
     ]
    }
   ],
   "source": [
    "plotter(res_history, \"ResNet101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading weights of the vgg16 pre-trained model without including top layers... imagenet is a dataset on which vgg16 was trained...\n",
    "vgg16_model = VGG16(input_tensor = input, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "vgg_model = network(vgg16_model)\n",
    "\n",
    "adam = Adam(learning_rate=0.001) # ADAM optimizer was used to reach the optimal weights...\n",
    "vgg_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fitting/training model...\n",
    "vgg_history = vgg_model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch = len(train) / BATCH_SIZE, # number of steps in each epoch...\n",
    "    callbacks=vgg_checkpoint,\n",
    "    epochs = EPOCHS, \n",
    "    validation_data = valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(vgg_history, \"VGG16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_results = vgg_model.evaluate(test_generator)\n",
    "print(f\"Accuracy of Inception v3 transfer learning model is: {vgg_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading weights of the InceptionV3 pre-trained model without including top layers... imagenet is a dataset on which InceptionV3 was trained...\n",
    "inception_model = InceptionV3(input_tensor = input, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "incepV3_model = network(inception_model)\n",
    "\n",
    "adam = Adam(learning_rate=0.001) # ADAM optimizer was used to reach the optimal weights...\n",
    "incepV3_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fitting/training model...\n",
    "incepV3_history = incepV3_model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch = len(train) / BATCH_SIZE, # number of steps in each epoch...\n",
    "    callbacks=incepV3_checkpoint,\n",
    "    epochs = EPOCHS, \n",
    "    validation_data = valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(incepV3_history, \"InceptionV3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e49d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "incepV3_results = incepV3_model.evaluate(test_generator)\n",
    "print(f\"Accuracy of Inception v3 transfer learning model is: {incepV3_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb3ece3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = EfficientNetB0(include_top=False)\n",
    "base_model = Xception(weights = 'imagenet', include_top = False, input_shape = (256, 256, 3))\n",
    "base_model.trainable=False\n",
    "\n",
    "\n",
    "input_layer = base_model(input, training=False)\n",
    "\n",
    "Xception_model = Sequential()\n",
    "Xception_model.add(base_model)\n",
    "\n",
    "Xception_model.add(Flatten()) \n",
    "Xception_model.add(Activation('relu'))\n",
    "Xception_model.add(Dense(375)) \n",
    "Xception_model.add(Activation('softmax'))\n",
    "\n",
    "# pool = Flatten()(input_layer)\n",
    "# outputs = Dense(375, activation='softmax', dtype=tf.float32, name=\"Output_layer\")(pool)\n",
    "\n",
    "# Xception_model = Model(input, outputs,name=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20137939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 37.1840 - accuracy: 0.4592\n",
      "Epoch 00001: val_loss improved from inf to 24.46029, saving model to ../models\\efficient.h5\n",
      "3415/3415 [==============================] - 579s 169ms/step - loss: 37.1840 - accuracy: 0.4592 - val_loss: 24.4603 - val_accuracy: 0.6469\n",
      "Epoch 2/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 28.0520 - accuracy: 0.6665\n",
      "Epoch 00002: val_loss improved from 24.46029 to 19.70260, saving model to ../models\\efficient.h5\n",
      "3415/3415 [==============================] - 550s 161ms/step - loss: 28.0520 - accuracy: 0.6665 - val_loss: 19.7026 - val_accuracy: 0.7493\n",
      "Epoch 3/100\n",
      "3416/3415 [==============================] - ETA: 0s - loss: 24.6238 - accuracy: 0.7315\n",
      "Epoch 00003: val_loss improved from 19.70260 to 17.91088, saving model to ../models\\efficient.h5\n",
      "3415/3415 [==============================] - 543s 159ms/step - loss: 24.6238 - accuracy: 0.7315 - val_loss: 17.9109 - val_accuracy: 0.7893\n",
      "Epoch 4/100\n",
      " 997/3415 [=======>......................] - ETA: 6:13 - loss: 21.0441 - accuracy: 0.7693"
     ]
    }
   ],
   "source": [
    "adam = Adam(learning_rate=0.001) # ADAM optimizer was used to reach the optimal weights...\n",
    "Xception_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fitting/training model...\n",
    "Xception_history = Xception_model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch = len(train) / BATCH_SIZE, # number of steps in each epoch...\n",
    "    callbacks=eff_callbacks,\n",
    "    epochs = EPOCHS, \n",
    "    validation_data = valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bdad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(efficient_history, \"Xception\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
